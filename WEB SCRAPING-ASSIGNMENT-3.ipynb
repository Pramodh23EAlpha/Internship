{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd872d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required \n",
    "import re\n",
    "import pandas as pd\n",
    "import time # for adding  a delay between exxecution of code\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import urllib\n",
    "from selenium.common.exceptions import NoSuchElementException \n",
    "from selenium.common.exceptions import StaleElementReferenceException \n",
    "\n",
    "import warnings\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to remove the warnings\n",
    "\n",
    "DRIVER_PATH = r'C:\\Users\\pramo\\Downloads\\CromeDriver\\chromedriver.exe'   # path of the downloaded file from local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b091610",
   "metadata": {},
   "source": [
    "# 1. \n",
    "Write a python program which searches all the product under a particular product from www.amazon.in. \n",
    "The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search \n",
    "for guitars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501cc7c0",
   "metadata": {},
   "source": [
    "#  &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff7f4c2",
   "metadata": {},
   "source": [
    "# 2. \n",
    "In the above question, now scrape the following details of each product listed in first 3 pages of your \n",
    "search results and save it in a data frame and csv. In case if any product has less than 3 pages in search \n",
    "results then scrape all the products available under that product name. Details to be scraped are: \"Brand \n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and \n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b30080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "\n",
    "driver.get('https://www.amazon.in/') # open the link in crome using webdriver\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to remove the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "955c153b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search:guitar\n",
      "User entered : guitar\n",
      "['Intern INT-38C Acoustic Guitar Kit, With Bag, Strings, Pick And Strap, Blue', 'Kadence Frontier Jumbo Semi Acoustic Guitar With Die Cast Keys,Super Combo (Bag, 1 pack Strings, Strap, Picks, Capo, Tuner (black & stand)', 'Medellin 38\" Acoustic Guitar Blue Burst Carbon Fiber body+(Free Online Learning Course) - Durable Matt finish with handrest, strings, strap, bag, 3 Picks, capo, stand.'] ['₹2,250.00', '₹7,349.00', '₹2,499.00'] ['Intern', 'Kadence', 'medellin'] [' 7 Days Replacement ', ' 7 Days Replacement ', ' 7 Days Replacement '] ['   In stock.   ', '   In stock.   ', '   In stock.   ']\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"Search:\")  # taking input from the user\n",
    "\n",
    "print('User entered :', user_input)\n",
    "\n",
    "driver.find_element_by_xpath(\"//*[@id='twotabsearchtextbox']\").send_keys(user_input) # find search field\n",
    "driver.find_element_by_xpath(\"//*[@id='twotabsearchtextbox']\").send_keys(Keys.RETURN) # Submit/Enter after entering the value into the search field\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "\n",
    "Brandname_list = []    \n",
    "Productname_list = []   \n",
    "Price_list = []\n",
    "Expected_Delivery = []\n",
    "Products_URL = []\n",
    "Return_Exchange = []\n",
    "Availability = []\n",
    "\n",
    "\n",
    "Product__url_scrap = driver.find_elements_by_xpath('//h2[@class = \"a-size-mini a-spacing-none a-color-base s-line-clamp-4\"]/a')\n",
    "#print(Product_brand_name_scrap)\n",
    "        \n",
    "        \n",
    "for urls in Product__url_scrap:\n",
    "        Products_URL.append(urls.get_attribute('href'))  \n",
    "\n",
    "\n",
    "#print(Products_URL)    \n",
    "    \n",
    "for links_amzn in Products_URL[:3]:\n",
    "    \n",
    "    driver.get(links_amzn)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        Productname_list.append(driver.find_element_by_id(\"productTitle\").text)\n",
    "    except:\n",
    "        Productname_list.append('-')\n",
    "        \n",
    "        \n",
    "    try:       \n",
    "        Price_list.append(driver.find_element_by_xpath('//span[@class = \"a-offscreen\"]').get_attribute(\"textContent\"))\n",
    "    except:\n",
    "        Price_list.append('-')\n",
    "        \n",
    "    try:        \n",
    "        Brandname_list.append(driver.find_element_by_xpath('//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span ').get_attribute(\"textContent\"))\n",
    "    except:\n",
    "        Brandname_list.append('-')\n",
    "        \n",
    "    try:   \n",
    "        Return_Exchange.append(driver.find_element_by_xpath('//*[@id=\"RETURNS_POLICY\"]/span/div[2]/a').get_attribute(\"textContent\"))\n",
    "    except:\n",
    "        Return_Exchange.append('-')\n",
    "        \n",
    "    try:   \n",
    "        Availability.append(driver.find_element_by_xpath('//*[@id=\"availability\"]/span').get_attribute(\"textContent\"))\n",
    "    except:\n",
    "        Availability.append('-')        \n",
    "    try:   \n",
    "        Expected_Delivery.append(driver.find_element_by_xpath('//*[@id=\"ddmDeliveryMessage\"]/div/b').get_attribute(\"textContent\"))\n",
    "    except:\n",
    "        Expected_Delivery.append('-')\n",
    "        \n",
    "        \n",
    "    time.sleep(1)\n",
    "\n",
    "print(Productname_list,Price_list,Brandname_list,Return_Exchange,Availability)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6cc1c",
   "metadata": {},
   "source": [
    "# 3. \n",
    "Write a python program to access the search bar and search button on images.google.com and scrape 10\n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_google = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "\n",
    "driver_google.get('https://images.google.com/') # open the link in crome using webdriver\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to remove the warnings\n",
    "\n",
    "\n",
    "searchinput = ['fruits','cars','Machine Learning','Guitar','Cakes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f37e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_url = []\n",
    "\n",
    "def download_images_url():\n",
    "    \n",
    "    for img_url  in range(len(images_url)):        \n",
    "        #print(img_url)\n",
    "        urllib.request.urlretrieve(images_url[img_url], str(img_url)+\"testingdownload.png\")\n",
    "\n",
    "    print('images downloaded locally')    \n",
    "\n",
    "def getimages():\n",
    "    \n",
    "    global cnt_imgs\n",
    "    cnt_imgs += 1\n",
    "\n",
    "    url_scrap = driver_google.find_elements_by_xpath('//div[@class = \"bRMDJf islir\"]/img')\n",
    "\n",
    "    for urls in url_scrap[:10]:\n",
    "        url  = urls.get_attribute('src')\n",
    "        images_url.append(url)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    if(cnt_imgs < len(searchinput) ):\n",
    "                \n",
    "        driver_google.find_element_by_xpath('//*[@id=\"REsRA\"]').clear()\n",
    "        driver_google.find_element_by_xpath('//*[@id=\"REsRA\"]').send_keys(searchinput[cnt_imgs],Keys.RETURN)\n",
    "        time.sleep(3)\n",
    "        getimages()\n",
    "        \n",
    "    else:\n",
    "        download_images_url()\n",
    "        \n",
    "    print(len(images_url))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_imgs = 0\n",
    "driver_google.find_element_by_xpath('//*[@id=\"sbtc\"]/div/div[2]/input').send_keys(searchinput[0],Keys.RETURN) # find search field\n",
    "getimages()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a7fa93",
   "metadata": {},
   "source": [
    "# 4.\n",
    "Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on\n",
    "www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be \n",
    "scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, \n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the \n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07a42e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_flipokart = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "\n",
    "driver_flipokart.get('https://www.flipkart.com/') # open the link in crome using webdriver\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to remove the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fff9809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_input = input(\"Search:\")  # taking input from the user\n",
    "\n",
    "#print('User entered :', user_input)\n",
    "\n",
    "driver_flipokart.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input').send_keys(\"pixel 4A\",Keys.RETURN) # find search field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e3129c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\SOFTWARES\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:464: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24 24 24 24 24 24 24\n"
     ]
    }
   ],
   "source": [
    "Product_name_brand = []\n",
    "ram_rom = []\n",
    "display_size = []\n",
    "rear_camera = []\n",
    "front_camera = []\n",
    "battery_capacity = []\n",
    "prices = []\n",
    "Prod_url = []\n",
    "\n",
    "\n",
    "\n",
    "Product_brandname_scrap = driver_flipokart.find_elements_by_xpath('//div[@class= \"_4rR01T\"]')\n",
    "Product_info_scrap = driver_flipokart.find_elements_by_xpath('//ul[@class= \"_1xgFaf\"]')\n",
    "Product_price_scrap = driver_flipokart.find_elements_by_xpath('//div[@class = \"_30jeq3 _1_WHN1\"]')\n",
    "Product_urls_scrap = driver_flipokart.find_elements_by_class_name('_1fQZEK')\n",
    "\n",
    "for names in Product_brandname_scrap:\n",
    "    Product_name_brand.append(names.text)\n",
    "        \n",
    "for infos in Product_info_scrap:\n",
    "    dats = infos.find_elements_by_class_name('rgWa7D')\n",
    "    ram_rom.append(dats[0].text) \n",
    "    display_size.append(dats[1].text)\n",
    "    rear_camera.append(dats[2].text)\n",
    "    front_camera.append(dats[2].text) \n",
    "    battery_capacity.append(dats[3].text)\n",
    "        \n",
    "for price in Product_price_scrap:\n",
    "    prices.append(price.text)\n",
    "                                                              \n",
    "         \n",
    "for url in Product_urls_scrap:\n",
    "    Prod_url.append(url.get_attribute('href'))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "print(len(prices),len(Product_name_brand),len(display_size),len(rear_camera),len(front_camera),len(battery_capacity),len(prices),len(Prod_url))    \n",
    "\n",
    "flip =pd.DataFrame({})\n",
    "flip['Product Name']=Product_name_brand\n",
    "flip['Prices']=prices\n",
    "flip['Display Size']=display_size\n",
    "flip['Rear / Front Camera']=rear_camera\n",
    "#flip['Front Camera']=front_camera\n",
    "flip['Product URL']=Prod_url\n",
    "\n",
    "\n",
    "\n",
    "flip.to_csv(\"Flipkartdetails.csv\")\n",
    "flip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bff51c",
   "metadata": {},
   "source": [
    "# 5.\n",
    "Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google\n",
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f0f9b657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location :bangalore\n",
      "https://www.google.com/maps/@13.0282161,77.6879584,15z\n",
      "Latitude :  13.0282161\n",
      "Longitude :  77.6879584\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"Location :\")\n",
    "\n",
    "driver_gmap = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "\n",
    "driver_gmap.get('https://www.google.com/maps/') # open the link in crome using webdriver\n",
    "time.sleep(3)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to remove the warnings\n",
    "driver_gmap.find_element_by_xpath('//*[@id=\"searchboxinput\"]').send_keys(user_input,Keys.RETURN)\n",
    "print(driver_gmap.current_url)    \n",
    "lat = re.split(\"\\@(-?[\\d\\.]*)\", driver_gmap.current_url)\n",
    "Lon = re.split(\"\\@[-?\\d\\.]*\\,([-?\\d\\.]*)\", driver_gmap.current_url)\n",
    "\n",
    "\n",
    "print('Latitude : ',str(lat[1]))\n",
    "print('Longitude : ',str(Lon[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c114b",
   "metadata": {},
   "source": [
    "# 6.\n",
    "Write a program to scrap details of all the funding deals for second quarter (i.e Jan 21 – March 21) \n",
    "from trak.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6537aa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59e6d398",
   "metadata": {},
   "source": [
    "# 7. \n",
    "Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e396d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.digit.in/gaming-mart/topten/gaming-laptops/\n"
     ]
    }
   ],
   "source": [
    "driver_digit = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "\n",
    "driver_digit.get('https://www.digit.in/') # open the link in crome using webdriver\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to remove the warnings\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver_digit.find_element_by_xpath('/html/body/div[2]/div/div[4]/ul/li[8]/a').click()\n",
    "time.sleep(3)\n",
    "\n",
    "driver_digit.find_element_by_xpath('/html/body/div[2]/div/div/div/div[2]/ul/li[1]/a').click()\n",
    "time.sleep(3)\n",
    "\n",
    "gamin_lap_url = driver_digit.find_element_by_xpath('/html/body/div[4]/div/div[2]/ul/li[12]/span/a').get_attribute('href')\n",
    "\n",
    "print(gamin_lap_url)\n",
    "\n",
    "driver_digit.get(gamin_lap_url)\n",
    "\n",
    "time.sleep(3)\n",
    "driver_digit.find_element_by_xpath('/html/body/div[4]/div/div[2]/div[2]/div/a').click()\n",
    "\n",
    "driver_digit.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23a36ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01. MSI GF63 Thin', '02. Mi Notebook 14 Horizon Gray', '03. Lenovo IdeaPad 3', '04. Acer Nitro 5', '05. Acer Aspire 7', '06. Mi NoteBook 14 Horizon Edition', '07. ASUS TUF Ryzen 5 Core 3550H (2021)', '08. HP Pavilion Ryzen 5-3550H (2021)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "laptop_name_scrap = driver_digit.find_elements_by_xpath('//h2[@class = \"ga-fired\"]')\n",
    "\n",
    "\n",
    "lap_name = []\n",
    "\n",
    "for lap in laptop_name_scrap:\n",
    "    lap_name.append(lap.text)\n",
    "\n",
    "print('Laptop list : 'lap_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db51b7f",
   "metadata": {},
   "source": [
    "# 8. \n",
    "Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be \n",
    "scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver_forbes = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "\n",
    "driver_forbes.get('https://www.forbes.com/') # open the link in crome using webdriver\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to remove the warnings\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#driver_forbes.find_element_by_class_name('icon--hamburger').click()\n",
    "\n",
    "bill_link = driver_forbes.find_element_by_xpath('/html/body/div[1]/header/nav/div[3]/ul/li[1]/div[2]/ul/li[2]/a').get_attribute('href')\n",
    "\n",
    "driver_forbes.get(bill_link) # open the link in crome using webdriver\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "Forbes_Name = []\n",
    "Forbes_Age = []\n",
    "Forbes_Rank = []\n",
    "Forbes_Networth = []\n",
    "Forbes_Citizenship = []\n",
    "Forbes_Source = []\n",
    "Forbes_Industry = []\n",
    "\n",
    "\n",
    "\n",
    "forbesdata_scrap = driver_forbes.find_elements_by_xpath('//div[@role= \"row\"]')\n",
    "\n",
    "for forbes_data in forbesdata_scrap:\n",
    "    \n",
    "    Forbes_Name.append(forbes_data.find_element_by_class_name(\"personName\").text)\n",
    "    Forbes_Age.append(forbes_data.find_element_by_class_name(\"age\").text)\n",
    "    Forbes_Rank.append(forbes_data.find_element_by_class_name(\"rank\").text)\n",
    "    Forbes_Networth.append(forbes_data.find_element_by_class_name(\"netWorth\").text)\n",
    "    Forbes_Citizenship.append(forbes_data.find_element_by_class_name(\"countryOfCitizenship\").text)\n",
    "    Forbes_Source.append(forbes_data.find_element_by_class_name(\"source\").text)\n",
    "    Forbes_Industry.append(forbes_data.find_element_by_class_name(\"category\").text)    \n",
    "    \n",
    "print(len(Forbes_Name),len(Forbes_Age),len(Forbes_Rank),len(Forbes_Networth),len(Forbes_Citizenship),len(Forbes_Source),len(Forbes_Industry))\n",
    "\n",
    "\n",
    "\n",
    "df=pd.DataFrame({\"Name\":Forbes_Name,\"Age\":Forbes_Age,\"Rank\":Forbes_Rank,\n",
    "                \"Networth\":Forbes_Networth ,\"Citizenship\":Forbes_Citizenship, \"Source\":Forbes_Source, \"Industry\":Forbes_Industry})\n",
    "df\n",
    "\n",
    "driver_forbes.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8312e0e",
   "metadata": {},
   "source": [
    "# 9. \n",
    "Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted \n",
    "from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96332bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_yt = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "\n",
    "driver_yt.get('https://www.youtube.com/watch?v=aJOTlE1K90k') # open the link in crome using webdriver\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to remove the warnings\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "while True:\n",
    "    scroll_height = 500\n",
    "    document_height_before = driver_yt.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    driver_yt.execute_script(f\"window.scrollTo(0, {document_height_before + scroll_height});\")\n",
    "    time.sleep(1.5)\n",
    "    document_height_after = driver_yt.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    if document_height_after == document_height_before:\n",
    "        break\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "driver_yt.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c27afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#driver_yt.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#time.sleep(6)\n",
    "\n",
    "\n",
    "yt_comment_scrap = driver_yt.find_elements_by_xpath('//yt-formatted-string[@id = \"content-text\"]')\n",
    "\n",
    "print(len(yt_comment_scrap))\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    scroll_height = 100\n",
    "    document_height_before = driver_yt.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    driver_yt.execute_script(f\"window.scrollTo(0, {document_height_before + scroll_height});\")\n",
    "    time.sleep(3)\n",
    "    document_height_after = driver_yt.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    if document_height_after == document_height_before:\n",
    "        break\n",
    "        \n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a28e1640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "yt_comment_scrap = driver_yt.find_elements_by_xpath('//yt-formatted-string[@id = \"content-text\"]')\n",
    "\n",
    "print(len(yt_comment_scrap))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73b60821",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-4b70b8e0bd32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mdriver_yt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"comment-section-renderer-items\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SOFTWARES\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_id\u001b[1;34m(self, id_)\u001b[0m\n\u001b[0;32m    471\u001b[0m         )\n\u001b[1;32m--> 472\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SOFTWARES\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m   1245\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\SOFTWARES\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m             response['value'] = self._unwrap_value(\n",
      "\u001b[1;32mE:\\SOFTWARES\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=97.0.4692.99)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D66903+2517251]\n\tOrdinal0 [0x00CFF8E1+2095329]\n\tOrdinal0 [0x00C02710+1058576]\n\tOrdinal0 [0x00BF76A4+1013412]\n\tOrdinal0 [0x00BF7EA8+1015464]\n\tOrdinal0 [0x00BF9695+1021589]\n\tOrdinal0 [0x00BF3686+996998]\n\tOrdinal0 [0x00C03A60+1063520]\n\tOrdinal0 [0x00C55382+1397634]\n\tOrdinal0 [0x00C4639B+1336219]\n\tOrdinal0 [0x00C227A7+1189799]\n\tOrdinal0 [0x00C23609+1193481]\n\tGetHandleVerifier [0x00EF5904+1577972]\n\tGetHandleVerifier [0x00FA0B97+2279047]\n\tGetHandleVerifier [0x00DF6D09+534521]\n\tGetHandleVerifier [0x00DF5DB9+530601]\n\tOrdinal0 [0x00D04FF9+2117625]\n\tOrdinal0 [0x00D098A8+2136232]\n\tOrdinal0 [0x00D099E2+2136546]\n\tOrdinal0 [0x00D13541+2176321]\n\tBaseThreadInitThunk [0x76C0FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77C37A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77C37A6E+238]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-4b70b8e0bd32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# otherwise, sleep for three seconds and try again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "driver_yt = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "\n",
    "driver_yt.get('https://www.youtube.com/watch?v=aJOTlE1K90k')\n",
    "time.sleep(3)\n",
    "\n",
    "# scroll to the bottom in order to load the comments\n",
    "driver_yt.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(3)\n",
    " \n",
    "# wait for the comments to load\n",
    "while True:\n",
    "    # if comments load, then break out of the while loop\n",
    "    try:\n",
    "        driver_yt.find_element_by_id(\"comment-section-renderer-items\")\n",
    "        break\n",
    "    # otherwise, sleep for three seconds and try again\n",
    "    except:\n",
    "        time.sleep(3)\n",
    "        continue\n",
    " \n",
    "# print the comments, separated by a line\n",
    "for item in driver_yt.find_elements_by_class_name(\"comment-renderer\"):\n",
    "    print (item.text)\n",
    "    print (\"-\"*80)\n",
    " \n",
    "# close the browser\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1dcbfb",
   "metadata": {},
   "source": [
    "# 10. \n",
    "Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in \n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, \n",
    "overall reviews, privates from price, dorms from price, facilities and property description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "641477a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "Hostel_Name = []\n",
    "Hostel_distance = []\n",
    "Hostel_rating = []\n",
    "Hostel_reviews_total = []\n",
    "Hostel_reviews_overall = []\n",
    "Hostel__privates_price = []\n",
    "Hostel_dorms_price = []\n",
    "Hostel_facilities = []\n",
    "Hostel_description = []\n",
    "\n",
    "\n",
    "\n",
    "driver_hostel = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "\n",
    "driver_hostel.get('https://www.hostelworld.com/') # open the link in crome using webdriver\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to remove the warnings\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "driver_hostel.find_element_by_class_name('field-inner').click()\n",
    "time.sleep(2)\n",
    "\n",
    "driver_hostel.find_element_by_id('search-input-field').send_keys(\"London\") # find search field\n",
    "time.sleep(3)\n",
    "\n",
    "driver_hostel.find_element_by_xpath('//*[@id=\"predicted-search-results\"]/li[2]').click() # find search field\n",
    "time.sleep(1)\n",
    "\n",
    "driver_hostel.find_element_by_id('search-button').click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hostel_Name = []\n",
    "Hostel_distance = []\n",
    "Hostel_rating = []\n",
    "Hostel_reviews_total = []\n",
    "Hostel_reviews_overall = []\n",
    "Hostel__privates_price = []\n",
    "Hostel_dorms_price = []\n",
    "Hostel_facilities = []\n",
    "Hostel_description = []\n",
    "hostel_button= []\n",
    "\n",
    "hostel_data_scrap = driver_hostel.find_elements_by_xpath('//*[@class = \"property\"]')\n",
    "dis = driver_hostel.find_elements_by_xpath('//span[@class=\"description\"]')\n",
    "revs_scrap = driver_hostel.find_elements_by_xpath('//div[@class=\"reviews\"]')\n",
    "prices_scrap = driver_hostel.find_elements_by_xpath('//div[@class = \"price-col\"]')\n",
    "btns_scrap = driver_hostel.find_elements_by_xpath('//h2[@class = \"title title-6\"]/a')\n",
    "\n",
    "pri_cnt = 0\n",
    "for pri in prices_scrap:\n",
    "    try: \n",
    "        if pri_cnt == 0:                        \n",
    "            Hostel__privates_price.append(pri.text)\n",
    "            pri_cnt = 1\n",
    "        else :\n",
    "            Hostel_dorms_price.append(pri.text)\n",
    "            pri_cnt = 0\n",
    "    except:\n",
    "        Hostel__privates_price.append('null')\n",
    "        \n",
    "        \n",
    "for d in dis:\n",
    "    try:       \n",
    "        Hostel_distance.append(d.text)\n",
    "    except:\n",
    "        Hostel_distance.append('null')\n",
    "        \n",
    "for urls in btns_scrap:\n",
    "    try:       \n",
    "        hostel_button.append(urls.get_attribute('href'))\n",
    "    except:\n",
    "        hostel_button.append('null')        \n",
    "        \n",
    "for rev in revs_scrap:\n",
    "    try:       \n",
    "        Hostel_reviews_total.append(rev.text)\n",
    "    except:\n",
    "        Hostel_reviews_total.append('null')       \n",
    "      \n",
    "    \n",
    "             \n",
    "hcnt = 2\n",
    "for hdata in hostel_data_scrap:\n",
    "            \n",
    "    hcnt = hcnt+ 1\n",
    "    try:       \n",
    "        Hostel_Name.append(hdata.find_element_by_tag_name('h2').text)\n",
    "        #hostel_button.append(hdata.get_attribute('href').text)\n",
    "    except:\n",
    "        Hostel_Name.append('null')\n",
    "\n",
    "    try:        \n",
    "        Hostel_rating.append(hdata.find_element_by_xpath('//*[@id=\"__layout\"]/div/div[1]/div[4]/div/div/div['+str(hcnt)+']/div[2]/div[2]/a/div/div[1]').text)\n",
    "    except NoSuchElementException as e:\n",
    "        \n",
    "        print('exception ')\n",
    "        #Hostel_rating.append('null')\n",
    "\n",
    "#//button[@class = \"button primary small full-width\"]\n",
    "print(len(Hostel_Name[1:]), len(Hostel_distance),len(Hostel_rating),len(Hostel_reviews_total),len(Hostel__privates_price),len(Hostel_dorms_price),len(hostel_button))\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hosteldf =pd.DataFrame({})\n",
    "hosteldf['Name']=Hostel_Name[1:]\n",
    "hosteldf['Distance']=Hostel_distance\n",
    "hosteldf['Rating']=Hostel_rating\n",
    "hosteldf['Total Reviews']=Hostel_reviews_total\n",
    "hosteldf['Private Prices']=Hostel__privates_price\n",
    "hosteldf['Dorms Prices']=Hostel_dorms_price\n",
    "\n",
    "\n",
    "hosteldf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe526dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hostel_Name = []\n",
    "Hostel_distance = []\n",
    "Hostel_rating = []\n",
    "Hostel_reviews_total = []\n",
    "Hostel_reviews_overall = []\n",
    "Hostel__privates_price = []\n",
    "Hostel_dorms_price = []\n",
    "Hostel_facilities = []\n",
    "Hostel_description = []\n",
    "hostel_button= []\n",
    "\n",
    "hostel_data_scrap = driver_hostel.find_elements_by_xpath('//*[@class = \"property\"]')\n",
    "dis = driver_hostel.find_elements_by_xpath('//span[@class=\"description\"]')\n",
    "revs_scrap = driver_hostel.find_elements_by_xpath('//div[@class=\"reviews\"]')\n",
    "prices_scrap = driver_hostel.find_elements_by_xpath('//div[@class = \"price-col\"]')\n",
    "btns_scrap = driver_hostel.find_elements_by_xpath('//h2[@class = \"title title-6\"]/a')\n",
    "\n",
    "pri_cnt = 0\n",
    "for pri in prices_scrap:\n",
    "    try: \n",
    "        if pri_cnt == 0:                        \n",
    "            Hostel__privates_price.append(pri.text)\n",
    "            pri_cnt = 1\n",
    "        else :\n",
    "            Hostel_dorms_price.append(pri.text)\n",
    "            pri_cnt = 0\n",
    "    except:\n",
    "        Hostel__privates_price.append('null')\n",
    "        \n",
    "        \n",
    "for d in dis:\n",
    "    try:       \n",
    "        Hostel_distance.append(d.text)\n",
    "    except:\n",
    "        Hostel_distance.append('null')\n",
    "        \n",
    "for urls in btns_scrap:\n",
    "    try:       \n",
    "        hostel_button.append(urls.get_attribute('href'))\n",
    "    except:\n",
    "        hostel_button.append('null')        \n",
    "        \n",
    "for rev in revs_scrap:\n",
    "    try:       \n",
    "        Hostel_reviews_total.append(rev.text)\n",
    "    except:\n",
    "        Hostel_reviews_total.append('null')       \n",
    "      \n",
    "    \n",
    "             \n",
    "hcnt = 2\n",
    "for hdata in hostel_data_scrap:\n",
    "            \n",
    "    hcnt = hcnt+ 1\n",
    "    try:       \n",
    "        Hostel_Name.append(hdata.find_element_by_tag_name('h2').text)\n",
    "        #hostel_button.append(hdata.get_attribute('href').text)\n",
    "    except:\n",
    "        Hostel_Name.append('null')\n",
    "\n",
    "    try:        \n",
    "        Hostel_rating.append(hdata.find_element_by_xpath('//*[@id=\"__layout\"]/div/div[1]/div[4]/div/div/div['+str(hcnt)+']/div[2]/div[2]/a/div/div[1]').text)\n",
    "    except NoSuchElementException as e:\n",
    "        \n",
    "        print('exception ')\n",
    "        #Hostel_rating.append('null')\n",
    "\n",
    "#//button[@class = \"button primary small full-width\"]\n",
    "print(len(Hostel_Name[1:]), len(Hostel_distance),len(Hostel_rating),len(Hostel_reviews_total),len(Hostel__privates_price),len(Hostel_dorms_price),len(hostel_button))\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hosteldf =pd.DataFrame({})\n",
    "hosteldf['Name']=Hostel_Name[1:]\n",
    "hosteldf['Distance']=Hostel_distance\n",
    "hosteldf['Rating']=Hostel_rating\n",
    "hosteldf['Total Reviews']=Hostel_reviews_total\n",
    "hosteldf['Private Prices']=Hostel__privates_price\n",
    "hosteldf['Dorms Prices']=Hostel_dorms_price\n",
    "\n",
    "\n",
    "hosteldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad840c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d964d840",
   "metadata": {},
   "source": [
    "## Web Scraping using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548f479",
   "metadata": {},
   "source": [
    "## 1) Write a python program to display all the header tags from wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860675e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def geturlfromuser(userinput):\n",
    "    \n",
    "\n",
    "    page = requests.get(userinput)\n",
    "    page\n",
    "\n",
    "    bsoup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    headertags = bsoup.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "    print('List of all the header tags :', *headertags, sep='\\n\\n')\n",
    "    \n",
    "    \n",
    "userinput = input(\"Enter the website here\")\n",
    "geturlfromuser(userinput)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e16aa",
   "metadata": {},
   "source": [
    "    \n",
    "## 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.imdb.com/chart/top\n",
    "data = pd.DataFrame()\n",
    "\n",
    "def geturlfromuser(userinput):\n",
    "    \n",
    "\n",
    "    page = requests.get(userinput)\n",
    "    bsoup = BeautifulSoup(page.content, 'html.parser')\n",
    "    #secondaryInfo\n",
    "    movies_imdb = bsoup.find_all('td',class_ = 'titleColumn')\n",
    "    scraped_ratings = bsoup.find_all('td', class_='ratingColumn imdbRating')\n",
    "    movie_year = bsoup.find_all('span',class_ = 'secondaryInfo')\n",
    "\n",
    "    #print(movie_year)\n",
    "    \n",
    "    movies = []\n",
    "    ratings = []\n",
    "    years = []\n",
    "\n",
    "    for movie in movies_imdb:\n",
    "        movies.append(movie.find('a').text)        \n",
    "    #print(movies)\n",
    "    data['Movie Names'] = movies\n",
    "    \n",
    "    for year in movie_year:  \n",
    "        year = year.get_text().replace('\\n', \"\")\n",
    "        year = year.strip(\" \")\n",
    "        years.append(year)        \n",
    "    #print(years)\n",
    "    data['Year'] = years\n",
    "    \n",
    "    \n",
    "    for rating in scraped_ratings:\n",
    "        rating = rating.get_text().replace('\\n', '')\n",
    "        ratings.append(rating)\n",
    "    #print(ratings)\n",
    "    data['Ratings'] = ratings\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "userinput = input(\"Enter the website here\")\n",
    "geturlfromuser(userinput) \n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f57c4",
   "metadata": {},
   "source": [
    "## 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.imdb.com/india/top-rated-indian-movies/\n",
    "data = pd.DataFrame()\n",
    "\n",
    "def geturlfromuser(userinput):\n",
    "    \n",
    "\n",
    "    page = requests.get(userinput)\n",
    "    bsoup = BeautifulSoup(page.content, 'html.parser')\n",
    "    #secondaryInfo\n",
    "    movies_imdb = bsoup.find_all('td',class_ = 'titleColumn')\n",
    "    scraped_ratings = bsoup.find_all('td', class_='ratingColumn imdbRating')\n",
    "    movie_year = bsoup.find_all('span',class_ = 'secondaryInfo')\n",
    "\n",
    "    #print(movie_year)\n",
    "    \n",
    "    movies = []\n",
    "    ratings = []\n",
    "    years = []\n",
    "\n",
    "    for movie in movies_imdb:\n",
    "        movies.append(movie.find('a').text)        \n",
    "    #print(movies)\n",
    "    data['Movie Names'] = movies\n",
    "    \n",
    "    for year in movie_year:  \n",
    "        year = year.get_text().replace('\\n', \"\")\n",
    "        year = year.strip(\" \")\n",
    "        years.append(year)        \n",
    "    #print(years)\n",
    "    data['Year'] = years\n",
    "    \n",
    "    \n",
    "    for rating in scraped_ratings:\n",
    "        rating = rating.get_text().replace('\\n', '')\n",
    "        ratings.append(rating)\n",
    "    #print(ratings)\n",
    "    data['Ratings'] = ratings\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "userinput = input(\"Enter the website here\")\n",
    "geturlfromuser(userinput) \n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f8401",
   "metadata": {},
   "source": [
    "## 4) Write a python program to scrape product name, price and discounts from https://meesho.com/bags\u0002ladies/pl/p7vbp . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "def geturlfromuser(userinput):\n",
    "    \n",
    "\n",
    "    page = requests.get(userinput)\n",
    "    print(page)\n",
    "    bsoup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    meesho_productnames = bsoup.find_all('p',class_ = 'Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS')\n",
    "    meesho_productprices = bsoup.find_all('h5')\n",
    "    meesho_productdiscount = bsoup.find_all('p',class_ = 'Text__StyledText-sc-oo0kvp-0 fCJVtz NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm')\n",
    "\n",
    "    #print(meesho_productprices)\n",
    "    products = []\n",
    "    prices = []\n",
    "    discounts = []\n",
    "    \n",
    "    for product in meesho_productnames:\n",
    "        product = product.get_text().replace('\\n', \"\")\n",
    "        product = product.strip(\" \")\n",
    "        products.append(product)\n",
    "    #print(products)\n",
    "    data['Products Name'] = products\n",
    "\n",
    "\n",
    "    for price in meesho_productprices:\n",
    "        prices.append(price.text)  \n",
    "    #print(prices)\n",
    "    data['Products Price'] = prices\n",
    "    \n",
    "    \n",
    "    for discount in meesho_productdiscount:\n",
    "        discount = discount.get_text().replace('\\n', \"\")\n",
    "        discount = discount.strip(\" \")\n",
    "        discounts.append(discount)\n",
    "    #print(discounts)\n",
    "    data['Products Discount'] = discounts\n",
    "  \n",
    "  \n",
    "userinput = input(\"Enter the website here\")\n",
    "geturlfromuser(userinput) \n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b6699a",
   "metadata": {},
   "source": [
    "## 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "## a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "## b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "## c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "## 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.icc-cricket.com/rankings/mens/team-rankings/odi\n",
    "data = pd.DataFrame()\n",
    "\n",
    "def geturlfromuser(userinput):\n",
    "    \n",
    "\n",
    "    page = requests.get(userinput)\n",
    "    print(page)\n",
    "    bsoup = BeautifulSoup(page.content, 'html.parser')\n",
    "    top_oditeams = bsoup.find_all('span',class_ = 'u-show-phablet')\n",
    "    \n",
    "    teams = []\n",
    "    for team in top_oditeams:\n",
    "        team = team.get_text().replace('\\n', \"\")\n",
    "        team = team.strip(\" \")\n",
    "        teams.append(team)\n",
    "    print(teams)    \n",
    "    \n",
    "    \n",
    "userinput_odi_teams = input(\"Enter to get Top 10 ODI teams\")\n",
    "userinput_odi_batsman = input(\"Enter to get  Top 10 ODI Batsmen\")\n",
    "userinput_odi_bowlers = input(\"Enter to get Top 10 ODI bowlers \")\n",
    "\n",
    "geturlfromuser(userinput_odi_teams) \n",
    "#data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ca57f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d964d840",
   "metadata": {},
   "source": [
    "## Web Scraping using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2083d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548f479",
   "metadata": {},
   "source": [
    "## 1) Write a python program to display all the header tags from wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860675e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def geturlfromuser(userinput):\n",
    "    \n",
    "\n",
    "    page = requests.get(userinput)\n",
    "    page\n",
    "\n",
    "    bsoup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    headertags = bsoup.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "    print('List of all the header tags :', *headertags, sep='\\n\\n')\n",
    "    \n",
    "    \n",
    "userinput = input(\"Enter the website here\")\n",
    "geturlfromuser(userinput)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e16aa",
   "metadata": {},
   "source": [
    "    \n",
    "## 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.imdb.com/chart/top\n",
    "data = pd.DataFrame()\n",
    "\n",
    "def geturlfromuser(userinput):\n",
    "    \n",
    "\n",
    "    page = requests.get(userinput)\n",
    "    bsoup = BeautifulSoup(page.content, 'html.parser')\n",
    "    #secondaryInfo\n",
    "    movies_imdb = bsoup.find_all('td',class_ = 'titleColumn')\n",
    "    scraped_ratings = bsoup.find_all('td', class_='ratingColumn imdbRating')\n",
    "    movie_year = bsoup.find_all('span',class_ = 'secondaryInfo')\n",
    "\n",
    "    #print(movie_year)\n",
    "    \n",
    "    movies = []\n",
    "    ratings = []\n",
    "    years = []\n",
    "\n",
    "    for movie in movies_imdb:\n",
    "        movies.append(movie.find('a').text)        \n",
    "    #print(movies)\n",
    "    data['Movie Names'] = movies\n",
    "    \n",
    "    for year in movie_year:  \n",
    "        year = year.get_text().replace('\\n', \"\")\n",
    "        year = year.strip(\" \")\n",
    "        years.append(year)        \n",
    "    #print(years)\n",
    "    data['Year'] = years\n",
    "    \n",
    "    \n",
    "    for rating in scraped_ratings:\n",
    "        rating = rating.get_text().replace('\\n', '')\n",
    "        ratings.append(rating)\n",
    "    #print(ratings)\n",
    "    data['Ratings'] = ratings\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "userinput = input(\"Enter the website here\")\n",
    "geturlfromuser(userinput) \n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d456641",
   "metadata": {},
   "source": [
    "## 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f8d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.imdb.com/india/top-rated-indian-movies/\n",
    "data = pd.DataFrame()\n",
    "\n",
    "def geturlfromuser(userinput):\n",
    "    \n",
    "\n",
    "    page = requests.get(userinput)\n",
    "    bsoup = BeautifulSoup(page.content, 'html.parser')\n",
    "    #secondaryInfo\n",
    "    movies_imdb = bsoup.find_all('td',class_ = 'titleColumn')\n",
    "    scraped_ratings = bsoup.find_all('td', class_='ratingColumn imdbRating')\n",
    "    movie_year = bsoup.find_all('span',class_ = 'secondaryInfo')\n",
    "\n",
    "    #print(movie_year)\n",
    "    \n",
    "    movies = []\n",
    "    ratings = []\n",
    "    years = []\n",
    "\n",
    "    for movie in movies_imdb:\n",
    "        movies.append(movie.find('a').text)        \n",
    "    #print(movies)\n",
    "    data['Movie Names'] = movies\n",
    "    \n",
    "    for year in movie_year:  \n",
    "        year = year.get_text().replace('\\n', \"\")\n",
    "        year = year.strip(\" \")\n",
    "        years.append(year)        \n",
    "    #print(years)\n",
    "    data['Year'] = years\n",
    "    \n",
    "    \n",
    "    for rating in scraped_ratings:\n",
    "        rating = rating.get_text().replace('\\n', '')\n",
    "        ratings.append(rating)\n",
    "    #print(ratings)\n",
    "    data['Ratings'] = ratings\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "userinput = input(\"Enter the website here\")\n",
    "geturlfromuser(userinput) \n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6300d1",
   "metadata": {},
   "source": [
    "## 4) Write a python program to scrape product name, price and discounts from https://meesho.com/bags\u0002ladies/pl/p7vbp . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b65b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "def geturlfromuser(userinput):\n",
    "    \n",
    "\n",
    "    page = requests.get(userinput)\n",
    "    bsoup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    meesho_productnames = bsoup.find_all('p',class_ = 'Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS')\n",
    "    meesho_productprices = bsoup.find_all('h5')\n",
    "    meesho_productdiscount = bsoup.find_all('p',class_ = 'Text__StyledText-sc-oo0kvp-0 fCJVtz NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm')\n",
    "\n",
    "    #print(meesho_productprices)\n",
    "    products = []\n",
    "    prices = []\n",
    "    discounts = []\n",
    "    \n",
    "    for product in meesho_productnames:\n",
    "        product = product.get_text().replace('\\n', \"\")\n",
    "        product = product.strip(\" \")\n",
    "        products.append(product)\n",
    "    #print(products)\n",
    "    data['Products Name'] = products\n",
    "\n",
    "\n",
    "    for price in meesho_productprices:\n",
    "        prices.append(price.text)  \n",
    "    #print(prices)\n",
    "    data['Products Price'] = prices\n",
    "    \n",
    "    \n",
    "    for discount in meesho_productdiscount:\n",
    "        discount = discount.get_text().replace('\\n', \"\")\n",
    "        discount = discount.strip(\" \")\n",
    "        discounts.append(discount)\n",
    "    #print(discounts)\n",
    "    data['Products Discount'] = discounts\n",
    "  \n",
    "  \n",
    "userinput = input(\"Enter the website here\")\n",
    "geturlfromuser(userinput) \n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c925c2",
   "metadata": {},
   "source": [
    "## 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "## a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "## b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "## c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "## 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f3631a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['32', '3,793', '28', '3,244', '32', '3,624', '25', '2,459', '27', '2,524', '30', '2,740', '30', '2,523', '32', '2,657', '17', '1,054', '7', '336', '25', '1,145', '10', '452', '20', '764', '14', '524', '11', '330', '9', '190', '14', '232', '6', '97', '13', '0']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Team Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>121               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team Name                                       Team Ratings\n",
       "0   New Zealand                              121               ...\n",
       "1       England                                                119\n",
       "2     Australia                                                116\n",
       "3         India                                                113\n",
       "4  South Africa                                                 98\n",
       "5      Pakistan                                                 93\n",
       "6    Bangladesh                                                 91\n",
       "7   West Indies                                                 84\n",
       "8     Sri Lanka                                                 83\n",
       "9   Afghanistan                                                 62"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.icc-cricket.com/rankings/mens/team-rankings/odi\n",
    "data = pd.DataFrame()\n",
    "\n",
    "def geturlfromuser(userinput):\n",
    "    \n",
    "\n",
    "    page = requests.get(userinput)\n",
    "\n",
    "    bsoup = BeautifulSoup(page.content, 'html.parser')\n",
    "    top_oditeams = bsoup.find_all('span',class_ = 'u-hide-phablet')\n",
    "    top_oditeams_matches= bsoup.find_all('td',class_ = 'table-body__cell u-center-text')\n",
    "    top_oditeams_ratings = bsoup.find_all('td',class_ = ['table-body__cell u-text-right rating','rankings-block__banner--rating u-text-right'])\n",
    "    #top_oditeams_points = bsoup.find_all('td',class_ = 'table-body__cell u-center-text')\n",
    "    teams = []\n",
    "    matches=[]\n",
    "    ratings = []\n",
    "    for team in top_oditeams:\n",
    "        if len(team.get_text(strip=True)) != 0:\n",
    "            team.extract()  \n",
    "            team = team.get_text().replace('\\n', \"\")\n",
    "            teams.append(team)\n",
    "    #print(teams)  \n",
    "    data['Team Name'] = teams[:10]\n",
    "    \n",
    "    for match in top_oditeams_matches:\n",
    "        match = match.get_text().replace('\\n', \"\")\n",
    "        #match = match.strip(\" \")\n",
    "        matches.append(match)\n",
    "    print(matches)    \n",
    "    #data['Team Matches and Points'] = matches\n",
    "    \n",
    "    for rating in top_oditeams_ratings:\n",
    "        rating = rating.get_text().replace('\\n', \"\")\n",
    "        ratings.append(rating)\n",
    "    #print(ratings)\n",
    "    data['Team Ratings'] = ratings[:10]\n",
    "\n",
    "odi_teams = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "geturlfromuser(odi_teams) \n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82222ebf",
   "metadata": {},
   "source": [
    "## 7) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content\n",
    "## and the code for the video from the link for the youtube video from the post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78d1e3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com/embed/z0gguhEmWiY?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent\n",
      "https://www.youtube.com/embed/_P7X8tMplsw?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent\n",
      "https://www.youtube.com/embed/fKl2JW_qrso?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent\n",
      "https://www.youtube.com/embed/IEEhzQoKtQU?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent\n",
      "https://www.youtube.com/embed/mO_dS3rXDIs?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent\n",
      "https://www.youtube.com/embed/2Fp1N6dof0Y?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent\n",
      "https://www.youtube.com/embed/-nh9rCzPJ20?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent\n",
      "https://www.youtube.com/embed/06I63_p-2A4?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent\n",
      "https://www.youtube.com/embed/_JGmemuINww?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headings</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Tutorial: Zip Files – Creating and Extr...</td>\n",
       "      <td>November 19, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Data Science Tutorial: Analyzing the 20...</td>\n",
       "      <td>October 17, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Multiprocessing Tutorial: Run Code in P...</td>\n",
       "      <td>September 21, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Threading Tutorial: Run Code Concurrent...</td>\n",
       "      <td>September 12, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Update (2019-09-03)</td>\n",
       "      <td>September 3, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Quick Tip: The Difference Between “==” ...</td>\n",
       "      <td>August 6, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Tutorial: Calling External Commands Usi...</td>\n",
       "      <td>July 24, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Visual Studio Code (Windows) – Setting up a Py...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Visual Studio Code (Mac) – Setting up a Python...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clarifying the Issues with Mutable Default Arg...</td>\n",
       "      <td>April 24, 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headings                Date\n",
       "0  Python Tutorial: Zip Files – Creating and Extr...   November 19, 2019\n",
       "1  Python Data Science Tutorial: Analyzing the 20...    October 17, 2019\n",
       "2  Python Multiprocessing Tutorial: Run Code in P...  September 21, 2019\n",
       "3  Python Threading Tutorial: Run Code Concurrent...  September 12, 2019\n",
       "4                                Update (2019-09-03)   September 3, 2019\n",
       "5  Python Quick Tip: The Difference Between “==” ...      August 6, 2019\n",
       "6  Python Tutorial: Calling External Commands Usi...       July 24, 2019\n",
       "7  Visual Studio Code (Windows) – Setting up a Py...         May 1, 2019\n",
       "8  Visual Studio Code (Mac) – Setting up a Python...         May 1, 2019\n",
       "9  Clarifying the Issues with Mutable Default Arg...      April 24, 2019"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.icc-cricket.com/rankings/mens/team-rankings/odi\n",
    "data = pd.DataFrame()\n",
    "\n",
    "def geturlfromuser(userinput):\n",
    "    \n",
    "\n",
    "    page = requests.get(userinput)\n",
    "\n",
    "    bsoup = BeautifulSoup(page.content, 'html.parser')\n",
    "    scrapped_headings = bsoup.find_all('h2',class_ = 'entry-title')\n",
    "    scrapped_headings_date = bsoup.find_all('time',class_ = 'entry-time')\n",
    "    scrapped_videolink = bsoup.find_all('iframe',class_ = 'youtube-player')\n",
    "\n",
    "\n",
    "\n",
    "    headings=[]\n",
    "    dates = []\n",
    "    videos =[]\n",
    "    \n",
    "    for heading in scrapped_headings:\n",
    "        headings.append(heading.find('a').text)        \n",
    "    #print(headings)\n",
    "    data['Headings'] = headings\n",
    "    \n",
    "    \n",
    "\n",
    "    for date in scrapped_headings_date:\n",
    "        date = date.get_text().replace('\\n', \"\")\n",
    "        dates.append(date)\n",
    "    #print(dates)\n",
    "    data['Date'] = dates\n",
    "    \n",
    "    \n",
    "    for video in scrapped_videolink:\n",
    "        video = video.get('src')\n",
    "        videos.append(video)\n",
    "    print(*videos,sep='\\n')\n",
    "    #data['Video URL'] = videos\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "url = 'https://coreyms.com/'\n",
    "geturlfromuser(url) \n",
    "data.head(100)\n",
    "#soup.find(\"iframe\").get(\"src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2881a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
